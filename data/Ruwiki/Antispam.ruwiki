page!content:	= Ruwiki %RV#% Antispam
	Wiki-spam, like email spam, is a major problem. Ruwiki is going to have
	extensive configurable tools for fighting spam. As it is, there are
	several tools built into Ruwiki to assist in the fight against these
	pond scum, but the tool development is certainly not complete.
	
	== External URI Redirection
	Although this will not greatly assist in the reduction of wiki spam,
	all external \URIs are redirected through an URI on Google that is
	designed specifically to remove \PageRank from links. The mechanism
	currently works on all manually-specified external \URIs and is not
	configurable without changing the URI tokenisation code. Thus, links
	that are generated by \[ruby-talk:12345] will not be redirected through
	Google, but direct links will be.
	
	New to Ruwiki 0.9.1, \URIs may be whitelisted with
	<tt>./data/clean.uri</tt>. The list of \URIs in <tt>clean.uri</tt> are
	&#8220;extended&#8221; Ruby regular expressions, one optional
	expression to a line. Spaces are not significant and comments are
	allowed. If you want to recognise a space in your regular expression,
	do so either with a character class ([ ]) or the whitespace
	meta-character (\s). Hash marks must be escaped (\#) or they will be
	treated as comment markers. Blank or comment-only lines are ignored.
	All other lines will be joined together.
	
	As noted, this will not necessarily reduce wiki spam, but it will deny
	spammers the entire benefit of spamming a wiki implemented with Ruwiki.
	
	== Reacting to Spammers and Robots
	Ruwiki %RV#% includes the ability to present alternative versions of
	itself to certain user agents and/or IP addresses based on a list. In
	the future, both the lists and the faces presented will be configurable
	(highly configurable, at that -- watch this space), but in this version
	of Ruwiki, there are three possible versions to be displayed:
	# Normal Ruwiki. This is a normally displayable and editable wiki.
	# Read-only Ruwiki. This is displayed to benign robots and users who have demonstrated that they cannot be trusted with edit access. The primary effect is to make command pages neither indexable, archivable, nor link-followable, and to remove certain links from visibility for these user agents.
	# Forbidden Ruwiki. The user gets an HTTP response of 403 Forbidden. This is displayed to malign (email-collecting) robots and users who have demonstrated that they are malicious and bent upon defacing the wiki.
	
	While Ruwiki provides these lists, and provides an extensive list of
	both malign and benign robots, it is up to the administrators of the
	wiki to ensure that they are kept up to date.
	
	The lists themselves are &#8220;extended&#8221; Ruby regular
	expressions, one optional expression to a line. Spaces are not
	significant and comments are allowed. If you want to recognise a space
	in your regular expression, do so either with a character class ([ ]) or
	the whitespace meta-character (\s). Hash marks must be escaped (\#) or
	they will be treated as comment markers. Blank or comment-only lines are
	ignored. All other lines will be joined together.
	
	  foo
	  bar
	
	becomes:
	
	  %r{foo|bar}x
	
	The file are stored in the data directory for the running instance of
	Ruwiki (e.g., <tt>./data</tt>):
	
	  ./data/agents.banned
	  ./data/agents.readonly
	  ./data/hostip.banned
	  ./data/hostip.readonly
page!footer:	
page!header:	
properties!create-date:	1103593880
properties!creator:	
properties!creator-ip:	UNKNOWN
properties!edit-comment:	
properties!edit-date:	1103593880
properties!editable:	true
properties!editor:	
properties!editor-ip:	127.0.0.1
properties!entropy:	0.0
properties!html-headers:	
properties!indexable:	false
properties!project:	Ruwiki
properties!title:	Antispam
properties!topic:	Antispam
properties!version:	1
ruwiki!content-version:	2
ruwiki!version:	%RV#%
